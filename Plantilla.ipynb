{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entendimiento del caso:\n",
    "\n",
    "## Enfoque Analítico:\n",
    "Categorias: descriptivo, daignosttico, prescriptivo, predictivo, cognitivo.\n",
    "\n",
    "### Tarea de Aprendizaje:\n",
    "* Regresión [ ]\n",
    "* Clasificación [ ]\n",
    "* Agrupamiento [ ]\n",
    "### Tipo de Aprendizaje:\n",
    "Supervisado, no Supervisado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m datos\u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mruta\u001b[39m\u001b[38;5;124m'\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtipo de separación\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "datos= pd.read_csv('ruta', sep='tipo de separación', encoding = 'utf-8')\n",
    "datos= pd.read_excel('ruta', sep='tipo de separación', encoding = 'utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entendimiento de los datos:\n",
    "\n",
    "Ver a que se refieren las variables, sus rangos y su dominio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datos' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdatos\u001b[49m\u001b[38;5;241m.\u001b[39minfo()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'datos' is not defined"
     ]
    }
   ],
   "source": [
    "datos.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calidad:\n",
    "* Completitud\n",
    "* Unicidad\n",
    "* Consistencia\n",
    "* Validez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.isnull().sum() / datos.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.duplicated(keep = False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##datos.Cada_Variable.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##datos[Cada_Variable].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparación de datos:\n",
    "\n",
    "* One-Hot Encoder.\n",
    "* Bajar el dominio\n",
    "* Combinar variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import scipy.stats as stats\n",
    "import scipy.optimize as optimize\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "cmap = sns.diverging_palette(220, 20, as_cmap=True)\n",
    "\n",
    "sns.heatmap(\n",
    "    ##datos[Variables].corr(),\n",
    "    cmap=cmap,\n",
    "    vmin=-1, vmax=1,\n",
    "    annot=True\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##X_train, X_test, y_train, y_test = train_test_split(datos[Variables_Candidatas], datos[Variable_Objetivo], test_size=0.3, random_state=1)\n",
    "##X_train.shape, y_train.shape\n",
    "##X_test.shape, y_test.shape\n",
    "##regression = LinearRegression()\n",
    "##regression.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##f, axs = plt.subplots(1, len(candidatas), sharey=True, figsize=(20, 5), layout=\"constrained\")\n",
    "\n",
    "##for i in range(len(candidatas)):\n",
    "##    col = candidatas[i]\n",
    "##    x = X_train[col]\n",
    "##   m = regression.coef_[i]\n",
    "##    b = regression.intercept_\n",
    "##\n",
    "##    axs[i].plot(x, y_train, \"o\", alpha=0.1)\n",
    "##    axs[i].plot(x, x * m + b)\n",
    "##    axs[i].set_title(col)\n",
    "##print(\"Train:\", np.sqrt(mean_squared_error(y_train, regression.predict(X_train))))\n",
    "##print(\"Test:\", np.sqrt(mean_squared_error(y_test, regression.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame({\"columns\": candidatas, \"coef\": regression.coef_})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación\n",
    "* Arbol de Decisión: Solo Valores numericos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Para crear el arbol de decisión \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "# Para usar KNN como clasificador\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Para realizar la separación del conjunto de aprendizaje en entrenamiento y test.\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Para evaluar el modelo\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# Versiones anteriores a 1.2 de sklearn: from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Para búsqueda de hiperparámetros\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Para la validación cruzada\n",
    "from sklearn.model_selection import KFold \n",
    "#Librerías para la visualización\n",
    "import matplotlib.pyplot as plt\n",
    "# Seaborn\n",
    "import seaborn as sns \n",
    "from sklearn import tree\n",
    "import sklearn as sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se selecciona la variable objetivo, en este caso \"Renuncia\".\n",
    "Y=data_t['Renuncia']\n",
    "# Del conjunto de datos se elimina la variable \"Renuncia\".\n",
    "X=data_t.drop(['Renuncia'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbol = DecisionTreeClassifier(criterion='entropy', max_depth = 4, random_state = 0)\n",
    "arbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbol = arbol.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = arbol.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(Y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se puede visualizar la matriz de confusión\n",
    "#plot_confusion_matrix(arbol, X_test, Y_test)  \n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=arbol.classes_)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Exactitud: %.2f' % accuracy_score(Y_test, y_pred))\n",
    "print(\"Recall: {}\".format(recall_score(Y_test,y_pred)))\n",
    "print(\"Precisión: {}\".format(precision_score(Y_test,y_pred)))\n",
    "print(\"Puntuación F1: {}\".format(f1_score(Y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar reporte de clasificación\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener la importancia de las variables. Para esto podemos utilizar uno de los atributos del modelo \"feature_importances_\", el\n",
    "# cual nos devuelve un coeficiente o peso para cada atributo: mientras más grande sea este más importante será la variable\n",
    "# asociada.\n",
    "importancia= arbol.feature_importances_\n",
    "importancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importancia_atributo = pd.DataFrame(data={\"Atributo\": X_train.columns,\"Importancia\": importancia})\n",
    "importancia_atributo = importancia_atributo.sort_values(by='Importancia', ascending=False).reset_index(drop=True)\n",
    "importancia_atributo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25,10))\n",
    "_ = tree.plot_tree(arbol, max_depth=arbol.get_depth(), feature_names=X.columns, class_names=[\"0\", \"1\"], filled=True, fontsize=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HiperParametros: GritSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fijemos el número de particiones. Utilizaremos K = 10.\n",
    "particiones = KFold(n_splits=10, shuffle=True, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Establecemos el espacio de búsqueda para los hiperparámetros que deseamos ajustar. \n",
    "param_grid = {'criterion':['gini', 'entropy'],'max_depth':[4,6,8,10,20]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Definimos el modelo sin ningún valor de estos hiperparámetros\n",
    "arbol = DecisionTreeClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Ahora utilizamos GridSearch sobre el grid definido y con 10 particiones en la validación cruzada.\n",
    "mejor_modelo = GridSearchCV(arbol, param_grid, cv=particiones)\n",
    "# Ajuste del modelo\n",
    "mejor_modelo.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos ver cuál fue el resultado de la búsqueda (mejores valores de hiperparámetros)\n",
    "mejor_modelo.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Obtener el mejor modelo.\n",
    "arbol_final = mejor_modelo.best_estimator_\n",
    "# Probemos ahora este modelo sobre test.\n",
    "y_pred_train = arbol_final.predict(X_train)\n",
    "y_pred_test = arbol_final.predict(X_test)\n",
    "print('Exactitud sobre entrenamiento: %.2f' % accuracy_score(Y_train, y_pred_train))\n",
    "print('Exactitud sobre test: %.2f' % accuracy_score(Y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agrupación\n",
    "* K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()  # for plot styling\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D # for 3D plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Supongamos que los expertos quieren ver relaciones entre las variables: \"Time\",\"Number_of_Casualties\",\"Day_of_Week\",\"Speed_limit\", \"Light_Conditions\"\n",
    "cols_select=[\"Time\",\"Number_of_Casualties\",\"Day_of_Week\",\"Speed_limit\", \"Light_Conditions\"]\n",
    "df_bicis_cols_sels=df_bicis[cols_select].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distortion(data,\n",
    "                    k_min=1, \n",
    "                    k_max=11,\n",
    "                    ylabel = 'Distortion',\n",
    "                    xlabel = 'Number of clusters',\n",
    "                    title = 'Distortion Plot'):\n",
    "    '''\n",
    "    Graficar el codo de los clusters\n",
    "    \n",
    "    Parametros\n",
    "    ----------\n",
    "    data : np.array\n",
    "        El arreglo con los datos\n",
    "    k_min : int\n",
    "        Valor mínimo para k\n",
    "    k_max : int\n",
    "        Valor máximo para k\n",
    "    xlabel : string\n",
    "        La etiqueta del eje x\n",
    "    ylabel  string\n",
    "        La etiqueta del eje y    \n",
    "    title : string\n",
    "        El titulo de la gráfica  \n",
    "    '''\n",
    "    distortions = []\n",
    "    for i in range(k_min, k_max):\n",
    "        km = KMeans(n_clusters=i,\n",
    "                 init='k-means++',\n",
    "                 n_init=10,\n",
    "                 max_iter=300,\n",
    "                 random_state=0)\n",
    "        km.fit(data)\n",
    "        distortions.append(km.inertia_)\n",
    "    plt.plot(range(k_min,k_max), distortions, marker='o')\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En este gráfico vemos el punto en que cambia la pendiente y ese es el número sugerido para el valor de k o número de grupos.\n",
    "# En este caso un valor de 3\n",
    "plot_distortion(df_bicis_model2_norm[cols_transformed],1,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Vámos las relaciones entre todas las variables numércias\n",
    "sns.pairplot(df_bicis_cols_sels, height=3,kind='scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # El negocio quiere que empecemos con calma, así que nos sugiere crear dos agrupaciones - k=2\n",
    "model_kmeans = KMeans(n_clusters=2, random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Si te sale el error: AttributeError: 'NoneType' object has no attribute 'split'\n",
    "# al ejecutar este comando, puedes actualizr el  \"threadpoolctl\" a  3.1.0 con el comando pip install threadpoolctl==3.1.0\n",
    "# más información: https://github.com/scikit-learn/scikit-learn/issues/24238\n",
    "#Para ver la versión actual utiliza: print(sklearn.show_versions())\n",
    "res_kmeans = model_kmeans.fit(df_bicis_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisar la cantidad de registros en los grupos resultado\n",
    "labels = res_kmeans.labels_\n",
    "df_bicis_model['Cluster'] = labels\n",
    "\n",
    "cluster_distrib = df_bicis_model['Cluster'].value_counts()\n",
    "\n",
    "fig=plt.figure(figsize=(12,8))\n",
    "sns.barplot(x=cluster_distrib.index, y=cluster_distrib.values, color='b');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformar el contenido de las columnas a arreglo para facilitar aplicar funciones como las de visualización\n",
    "cols_number = df_bicis_model.to_numpy()\n",
    "cols_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=df_bicis_model, hue=\"Cluster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver gráficamente en dos dimensiones -de acuerdo con el análisis de la gráfica anterior- las diferentes agrupaciones para poderlas describir mejor\n",
    "# Recuerden que el describir los grupos es quizás una de las actividades más difíciles a nivel de la tarea de agrupación.\n",
    "plt.scatter(cols_number[labels == 0, 0], cols_number[labels == 0, 1], s = 100, marker='v', c = 'red', label = 'Agrupación 1')\n",
    "plt.scatter(cols_number[labels == 1, 0], cols_number[labels == 1, 1], s = 100, marker='o', c = 'blue', label = 'Agrupación 2')\n",
    "\n",
    "plt.scatter(res_kmeans.cluster_centers_[:, 0], res_kmeans.cluster_centers_[:, 1], s = 100, c = 'yellow', label = 'Centroids')\n",
    "plt.title('Agrupación de accidentes')\n",
    "plt.xlabel(cols_select[0])\n",
    "plt.ylabel(cols_select[1])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisemos los valores de los centroides de los clústeres generados. Esta información puede ser útil durante la evaluación cualitativa del modelo\n",
    "print('Centroides: [[',cols_select[0], ' ' , cols_select[1], ']]', res_kmeans.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos una función basada en el concepto de silueta\n",
    "def plot_silhouette(data, \n",
    "                    labels,\n",
    "                   ylabel = 'Grupos',\n",
    "                   xlabel = \"Coeficiente de silueta\",\n",
    "                   title = 'Gráfica de silueta'):\n",
    "    '''\n",
    "    Graficar la silueta de los clusters\n",
    "    \n",
    "    Parametros\n",
    "    ----------\n",
    "    data : np.array\n",
    "        El arreglo con los datos\n",
    "    labels : np.array\n",
    "        El arreglo con las etiquetas correspondientes\n",
    "    ylabel  string\n",
    "        La etiqueta del eje y\n",
    "    xlabel : string\n",
    "        La etiqueta del eje x\n",
    "    title : string\n",
    "        El titulo de la gráfica        \n",
    "    '''\n",
    "    cluster_labels = np.unique(labels)\n",
    "    print(cluster_labels)\n",
    "    n_clusters = cluster_labels.shape[0]\n",
    "    silhouette_vals = silhouette_samples(data,\n",
    "                                        labels,\n",
    "                                        metric='euclidean')\n",
    "    y_ax_lower, y_ax_upper = 0, 0\n",
    "    yticks = []\n",
    "    for i, c in enumerate(cluster_labels):\n",
    "        c_silhouette_vals = silhouette_vals[labels == c]\n",
    "        c_silhouette_vals.sort()\n",
    "        y_ax_upper += len(c_silhouette_vals)\n",
    "        color = cm.jet(float(i) / n_clusters)\n",
    "        plt.barh(range(y_ax_lower, y_ax_upper),\n",
    "                        c_silhouette_vals,\n",
    "                        height=1.0,\n",
    "                        edgecolor='none',\n",
    "                        color=color)\n",
    "        yticks.append((y_ax_lower + y_ax_upper) / 2.)\n",
    "        y_ax_lower += len(c_silhouette_vals)\n",
    "    silhouette_avg = np.mean(silhouette_vals)\n",
    "    plt.axvline(silhouette_avg,\n",
    "                color=\"red\",\n",
    "                linestyle=\"--\")\n",
    "    plt.yticks(yticks, cluster_labels+1)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizar los centroides de un cluster. En el ejemplo, el grupo 0. \n",
    "# En este caso dado que los datos están normalizados los valores de algunas variables son muy pequeños y no se observan en la gráfica, por ejemplo: Num_vehicles\n",
    "fig = plt.figure(figsize=(15, 7))\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(cols_transformed,res_kmeans2.cluster_centers_.tolist()[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizar los centroides de un cluster. En el ejemplo, el grupo 0. \n",
    "# En este caso dado que los datos están normalizados los valores de algunas variables son muy pequeños y no se observan en la gráfica, por ejemplo: Num_vehicles\n",
    "fig = plt.figure(figsize=(15, 7))\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(cols_transformed,res_kmeans2.cluster_centers_.tolist()[0])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
